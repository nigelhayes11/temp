import requests
import re
import sys
import urllib3
from bs4 import BeautifulSoup

# SSL uyarÄ±larÄ±nÄ± kapat
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# Ayarlar
REDIRECT_SOURCE = "http://raw.githack.com/eniyiyayinci/redirect-cdn/main/index.html"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
}

def get_active_domain():
    """YÃ¶nlendirme sayfasÄ±ndan gÃ¼ncel inattv domainini Ã§eker."""
    try:
        print("ğŸ” Aktif domain yÃ¶nlendirme sayfasÄ±ndan alÄ±nÄ±yor...")
        r = requests.get(REDIRECT_SOURCE, timeout=10)
        match = re.search(r'URL=(https?://[^">]+)', r.text)
        if match:
            domain = match.group(1).rstrip('/')
            print(f"âœ… Aktif domain bulundu: {domain}")
            return domain
    except Exception as e:
        print(f"âŒ Domain Ã§ekilirken hata: {e}")
    return None

def resolve_base_url(active_domain):
    """YayÄ±n sunucusunun base adresini bulur."""
    target = f"{active_domain}/channel.html?id=yayininat"
    try:
        r = requests.get(target, headers={**HEADERS, "Referer": active_domain + "/"}, timeout=10, verify=False)
        # Yeni yapÄ±daki URL patternini ara
        match = re.search(r'["\'](https?://[^\s"\']+?)/[\w\-]+/mono\.m3u8', r.text)
        if match:
            return match.group(1).rstrip('/') + "/"
        
        alt_match = re.search(r'["\'](https?://[a-z0-9.-]+\.(?:sbs|xyz|live|pw|site)/)', r.text)
        if alt_match:
            return alt_match.group(1).rstrip('/') + "/"
    except: pass
    return None

def main():
    active_domain = get_active_domain()
    if not active_domain:
        sys.exit("âŒ BaÅŸlangÄ±Ã§ domaini bulunamadÄ±.")

    base_url = resolve_base_url(active_domain)
    if not base_url:
        base_url = "https://mm9.d72577a9dd0ec19.sbs/" 
        print(f"âš ï¸ Sunucu otomatik bulunamadÄ±, fallback kullanÄ±lÄ±yor: {base_url}")
    else:
        print(f"âœ… YayÄ±n sunucusu tespit edildi: {base_url}")

    # GÃœNCEL KANAL LÄ°STESÄ° (Girintiler dÃ¼zeltildi)
    fixed_channels = {
        "zirve": "beIN Sports 1 A",
        "trgoals": "beIN Sports 1 B",
        "yayin1": "beIN Sports 1 C",
        "b2": "beIN Sports 2",
        "b3": "beIN Sports 3",
        "b4": "beIN Sports 4",
        "b5": "beIN Sports 5",
        "bm1": "beIN Sports 1 Max",
        "bm2": "beIN Sports 2 Max",
        "ss1": "S Sports 1",
        "ss2": "S Sports 2",
        "smarts": "Smart Sports",
        "sms2": "Smart Sports 2",
        "t1": "Tivibu Sports 1",
        "t2": "Tivibu Sports 2",
        "t3": "Tivibu Sports 3",
        "t4": "Tivibu Sports 4",
        "as": "A Spor",
        "trtspor": "TRT Spor",
        "trtspor2": "TRT Spor YÄ±ldÄ±z",
        "trt1": "TRT 1",
        "atv": "ATV",
        "tv85": "TV8.5",
        "nbatv": "NBA TV",
        "eu1": "Euro Sport 1",
        "eu2": "Euro Sport 2",
        "ex1": "TÃ¢bii 1",
        "ex2": "TÃ¢bii 2",
        "ex3": "TÃ¢bii 3",
        "ex4": "TÃ¢bii 4",
        "ex5": "TÃ¢bii 5",
        "ex6": "TÃ¢bii 6",
        "ex7": "TÃ¢bii 7",
        "ex8": "TÃ¢bii 8"
    }

    try:
        print("ğŸ“¡ CanlÄ± maÃ§lar taranÄ±yor...")
        resp = requests.get(active_domain, headers=HEADERS, timeout=10, verify=False)
        resp.encoding = "utf-8"
        soup = BeautifulSoup(resp.text, "html.parser")

        m3u_content = ["#EXTM3U"]
        
        # 1. CanlÄ± MaÃ§lar BÃ¶lÃ¼mÃ¼
        matches_tab = soup.find(id="matches-tab")
        if matches_tab:
            for a in matches_tab.find_all("a", href=re.compile(r'id=')):
                cid_match = re.search(r'id=([^&]+)', a["href"])
                name = a.find(class_="channel-name")
                status = a.find(class_="channel-status")
                if cid_match and name:
                    cid = cid_match.group(1)
                    title = f"{status.get_text(strip=True) if status else 'CANLI'} | {name.get_text(strip=True)}"
                    m3u_content.append(f'#EXTINF:-1 group-title="CanlÄ± MaÃ§lar",{title}')
                    m3u_content.append(f'#EXTVLCOPT:http-user-agent={HEADERS["User-Agent"]}')
                    m3u_content.append(f'#EXTVLCOPT:http-referrer={active_domain}/')
                    m3u_content.append(f'{base_url}{cid}/mono.m3u8')

        # 2. Sabit Kanallar BÃ¶lÃ¼mÃ¼
        for cid, name in fixed_channels.items():
            m3u_content.append(f'#EXTINF:-1 group-title="7/24 Kanallar",{name}')
            m3u_content.append(f'#EXTVLCOPT:http-user-agent={HEADERS["User-Agent"]}')
            m3u_content.append(f'#EXTVLCOPT:http-referrer={active_domain}/')
            m3u_content.append(f'{base_url}{cid}/mono.m3u8')

        with open("int.m3u", "w", encoding="utf-8") as f:
            f.write("\n".join(m3u_content))

        print(f"ğŸ BAÅARILI â†’ karsilasmalar2.m3u hazÄ±r. ({len(m3u_content)-1} kanal)")

    except Exception as e:
        print(f"âŒ Hata: {e}")

if __name__ == "__main__":
    main()
